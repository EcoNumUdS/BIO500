class: inverse, center, middle

# Automatisation de processus avec targets

<hr width="65%" size="0.3" color="orange" style="margin-top:-20px;"></hr>

---

# L'automatisation d'un processus

Un projet d'analyse de données comprend de nombreuses étapes, qui vont de la construction de la base de données, à la production du rapport, en passant par les analyses statistiques. L'ensemble du processus peut-être long et frustrant, surtout lorsque l'on a une boucle du genre : 

1. Lancer le code
2. Attendre qu'il s'exécute 
3. Découvrir un bug 
4. Recommencer la boucle

Des petites modifications en amont peuvent affecter toute la chaîne en aval. Inversement, parfois on a seulement besoin de refaire une figure sans avoir à refaire toute la chaîne. 

La programmation d'une séquence d'instructions permet de formaliser ce processus et de s'attarder seulement aux étapes qui doivent être mises à jour. 

---

# Qu'est-ce qu'un outil d'automatisation ?
 
**Définition**: un fichier qui contient un ensemble de directives qui sont exécutées par l'ordinateur. Les instructions et leurs dépendances sont spécifiées.

---

# Quel outil utiliser ?

<!-- Le `makefile` est sans contredit l'outil le plus commun et le plus puissant. Spécifique au système d'exploitation UNIX, il peut seulement être utilisé sur les Mac, Linux, et des machines virtuelles. Pas pratique pour les utilisateurs Windows ! -->

Nous utiliserons la librairie `targets` pour assurer la reproductibilité de la démarche entreprise dans le cours. L'ensemble des instructions nécessaires à la production du rapport, de la création de la base de données à la compilation du document écrit, seront contenues dans une séquence d'instructions, plus généralement appelée 'workflow' ou 'pipeline'.

---

# Introduction à `targets`

1. Consulter le [chapitre Targets](https://econumuds.github.io/BIO500/targets.html).
2. Regarder la [vidéo](https://player.vimeo.com/video/700982360?h=38c890bd4f) de présentation.
3. Explorer la [documentation](https://books.ropensci.org/targets/).

---

# Un exemple minimal 

1. Lire le fichier de données `data.txt`
2. Faire une régression linéaire 
3. Faire une figure et l'enregistrer

## Vous pouvez suivre avec le [chapitre Targets](https://econumuds.github.io/BIO500/targets.html) du livre

---

# Un exemple minimal 

## La structure de fichiers sur votre ordinateur 

```md
├── data             # Dossier de données
│   ├── data.txt     # Jeu de données

├── R                # Dossier de scripts R
│   ├── figure.R     # Fonction utilisée comme targets
│   ├── analyse.R    # Fonction utilisée comme targets

├── _targets.R       # Fichier targets qui définit le pipeline
```

---

# Un exemple minimal 

## Le fichier de données 

```{r}
data = read.table("exemple_targets/data/data.txt", header = T)
head(data) 
```

---
# Un exemple minimal 

## Le script `analyse.R`

```{r eval = FALSE}
resultat_modele = function(data) lm(data$Y~data$X)
```

---

# Un exemple minimal 

## Le script `figure.R`

```{r}
ma_figure = function(data, resultat_modele) {
    plot(data$X, data$Y, xlab = "X", ylab = "Y", 
    cex.axis = 1.5, cex.lab = 1.5, pch = 19)
    abline(resultat_modele)
}
```

---

# Un exemple minimal 

## Mise à jour de la séquence

Quatre éléments peuvent être modifiés : 

- Le fichier de données `data.txt`
- Les scripts `analyse.R` et `figure.R` 
- La figure

---

# Un exemple minimal 

## target : définition

Une `target` est une étape de la séquence d'instructions.  

Une `target` est au minimum une _cible_ (nom d'un objet) et une _dépendance_ (commande R) 

Une `target` produit un objet R qui est enregistré dans la mémoire de la session

Une _dépendance_ est une expression qui dépent d'une `target` précédente

Le package `targets` exécute seulement les targets qui ne sont pas à jour. 

---

# Un exemple minimal 

## Anatomie d'un fichier `_targets.R`

```{r eval = FALSE}
# _targets.R file
library(targets)
source("exemple_targets/R/analyse.R")
source("exemple_targets/R/figure.R")
tar_option_set(packages = c("MASS"))
list(
  tar_target(
    data, # Le nom de l'objet
    read.table("exemple_targets/data/data.txt", header = T) # Lecture du fichier
  ), 
  tar_target(
    resultat_modele, # Cible pour le modèle 
    mon_modele(data) # Exécution de l'analyse
  ),
  tar_target(
    figure, # Cible pour l'exécution de la figure
    ma_figure(data, resultat_modele) # Réalisation de la figure
  )
)
```

---

# Un exemple minimal 

## Construction de la séquence (pipeline)

La construction d'une séquence d'opération est l'étape la plus importante. Cette étape se fait essentiellement avec du papier et un crayon, il faut identifier les dépendences entre les fonctions et les objets. 

La `target` d'une étape est utilisée comme argument dans une étape suivante.

Une target est exécutée seulement lorsque la `target` dont elle dépend est plus récente que l'objet qu'elle  produit. 

---

# Un exemple minimal 

## La séquence

### 1. On peut visualiser la séquence

```{r eval = FALSE}
source("exemple_targets/_targets.R")
tar_glimpse()
```

### 2. Exécuter la séquence 

```{r eval = FALSE}
tar_make()
```

### 3. Visualiser les étapes qui sont à jour et celles qui ne le sont pas

```{r eval = FALSE}
tar_visnetwork()
```

---

# Un exemple minimal 

## Qu'est-ce qui fait une bonne target ?

Comme une fonction, une `target` peut faire trois choses : 

1. Produire des données 
2. Analyser des données
3. Résumer une analyse ou des données (e.g. figure, tableau)

Si une target est trop longue, vous avez avantage à la briser en petits morceaux pour que chaque étape soit vérifiée. 

Alternativement, pour une séquence d'analyse très compliquée, on pourrait vouloir regrouper les étapes pour éviter d'avoir une liste trop longue.  

---

# Un exemple minimal 

## Qu'est-ce qui fait une bonne `target` ? 

Le grain d'une séquence dépend donc d'un compromis : 

1. Les `targets` sont suffisamment importantes pour sauver du temps si elles sont ignorées (e.g. construire votre base de données et faire les injections) 
2. Suffisamment petites pour qu'il soit pertinent d'automatiser le processus
3. Retourne un seul objet qui 
  - est facile à comprendre et interpréter
  - pertinent pour le projet 
  - peut être sauvé comme objet

---

# Le `_targets.R` comme outil de reproductiblité

La rédaction du ficher `_targets.R` nous force à spécifier les différentes étapes de notre démarche, à identifier les entrées et les sorties de différentes instructions à l'ordinateur. De cette façon, le fichier `_targets.R` permet de documenter rigoureusement la démarche réalisée.

Il s'agit aussi d'un aide-mémoire qui permet de se rappeler des étapes.

---

# Bonnes pratiques

`targets` est une librairie de haut niveau pour utilisateurs expérimentés. 

Les erreurs sont difficiles à trouver et à régler. 

Il faut s'assurer que chaque étape fonctionne avant d'en ajouter une autre. Il faut donc construire progressivement sont fichier `_target.R` et s'assurer qu'une étape s'exécute parfaitement avant de passer à la suivante. 

---

# Pour plus d'information 

Manuel de targets [https://books.ropensci.org/targets/](https://books.ropensci.org/targets/)

---

# Exercice 

Construire un script `targets` qui contient les étapes suivantes : 

1. Tirer au hasard 1000 valeurs d'une distribution normale avec une moyenne de 1 et un écart-type de 1 `rnorn(1000, 1, 1)`
2. Faire un histogramme de ces 1000 valeurs `hist()`
3. Produire un document html avec RMarkdown 

Note : la commande pour compiler du markdown est `render("mon_rmarkdown.Rmd")`

Note : Alternativement, `tar_render()` peut être utilisé à la place de `render()` et de `tar_target()` pour compiler un document RMarkdown. *Voir la [documentation](https://docs.ropensci.org/tarchetypes/reference/tar_render.html).

---

# Nettoyage du dépôt en fin de script

Il arrive que certains scripts génèrent des fichiers temporaires qui ne doivent pas être conservés inutilement et être poussés sur github. 

Le fichier `.gitignore` vous permet d'identifier les fichiers qui ne doivent pas être versés sur le serveur. 

---

class: inverse, center, middle

# Travail pour la semaine

<hr width="65%" size="0.3" color="orange" style="margin-top:-20px;"></hr>

---

# Consignes

- Identifiez clairement vos questions de recherche
- Planifiez les requêtes à réaliser pour traiter les données
- Créez un dépôt github pour votre projet 
- Créez un cahier de laboratoire où sont notées toutes vos étapes
- Versez votre travail sur le dépôt en ligne
- Construire le `_targets.R` au fur et à mesure de vos progrès

---

# Fiche de lecture

Vous avez à lire "The FAIR Guiding Principles for scientific data management and stewardship" de Wilkinson (2016) et répondre aux questions suivante en une page maximum à remettre en PDF avant le cours du 31 mars :

    Quel est l'importance des données, des métadonnées et du code dans crise actuelle de la reproductibilité ?
    Pourquoi les principes FAIR ? Quelle est leur pertinence ?
    Quel est le lien entre les principes FAIR et la reproductibilité ?

[Wilkinson et al. 2016. The FAIR Guiding Principles for scientific data management and stewardship.](https://github.com/EcoNumUdS/BIO500/blob/master/lectures/wilkinson2016.pdf)

---

class: inverse, center, middle

# Débat : Intelligence artificielle et écologie, opportunité ou menace pour la rigueur scientifique ?

<hr width="65%" size="0.3" color="orange" style="margin-top:-20px;"></hr>

<br>
## 15 minutes pour préparer ses arguments
## 2 minutes pour présenter ses arguments
## 20 minutes de discussion dirigée
## 5 minutes vote et conclusion
<!-- 
    Sondage sur l’impact perçu des LLM.
    Conclusion sur les pistes pour une utilisation responsable.
-->

<!-- 
Points de réflexion :

  -  Fiabilité et biais : Les LLM peuvent-ils introduire des biais dans l'analyse des données écologiques ?
  -  Automatisation et créativité scientifique : Les LLM peuvent-ils renforcer la créativité ou risquent-ils de réduire l’esprit critique ?
  -  Accès aux données et reproductibilité : Les LLM facilitent-ils l’accès à des connaissances dispersées ou compliquent-ils la transparence des méthodes ?
  -  Éthique et impacts environnementaux : L'empreinte carbone des LLM est-elle compatible avec les objectifs de durabilité écologique ? 

Retour sur règles de l'université de Sherbrooke : 
- Responsabilité étudiants : https://www.usherbrooke.ca/intranet-education/fileadmin/sites/intranet-education/documents/Intranet/Reglements_facultaires/Informations_facultaires_VF_en_vigueur.pdf
- Lignes directrices : https://www.usherbrooke.ca/decouvrir/a-propos/priorites-institutionnelles/intelligence-artificielle/lignes-directrices-iag
- Biblio : https://libguides.biblio.usherbrooke.ca/IA
-->